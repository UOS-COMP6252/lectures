{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HTsa4o4TAkhT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision as vision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import SGD,Adam"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch normalization     \n",
        "Given a mini-batch of tensors $x_{ci}$ of dimension (S,C,H,W) where $c$ is the channel index and $i$ collectively refers to all other dimensions. \n",
        "\n",
        "Let $N=S\\times H\\times W$. Batch normalization computes the mean and variance of the batch (per channel) according to\n",
        "  $$\n",
        "    \\begin{align*}\n",
        "    \\mu_c&=\\frac{1}{N}\\sum_{i=1}^N x_{ci}\\\\\n",
        "    \\sigma^2_c&=\\frac{1}{N}\\sum_{i=1}^N \\left(x_{ci}-\\mu_c\\right)^2\n",
        "    \\end{align*}\n",
        "$$\n",
        "\n",
        "The normalized inputs are computed as follows:\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\hat{x}_{ci}=\\frac{x_{ic}-\\mu_c}{\\sqrt{\\sigma^2_c+\\epsilon}}\n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "Therefore, for each channel, the $\\hat{x}_{ci}$ have zero mean and unit variance. The output of the batch normalization layer is given by\n",
        "$$\n",
        "\\begin{align*}\n",
        "y_{ic}=\\gamma \\hat{x}_{ic}+\\beta\n",
        "\\end{align*}\n",
        "$$\n",
        "Where $\\gamma$ and $\\beta$ are **learnable** parameters."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Example\n",
        "- For simplicity we consider a  tensor with a single channel\n",
        "- Recall that batch normalization is done for each channel independently\n",
        "- In the example below we create an arbitrary tensor ```a```  of size ```(2,1,22)```\n",
        "- It represents two samples, each with a single channel representing a 2x2 tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 1, 2, 2]\n",
            "[[[[ 1.  2.]\n",
            "   [ 3.  4.]]]\n",
            "\n",
            "\n",
            " [[[ 5.  6.]\n",
            "   [ 7. 18.]]]]\n"
          ]
        }
      ],
      "source": [
        "x=torch.tensor([[1,2],[3,4]],dtype=torch.float32).unsqueeze(0)\n",
        "y=torch.tensor([[5,6],[7,18]],dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "a=torch.stack([x,y])\n",
        "print(list(a.size()))\n",
        "print(a.numpy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Manual Computation vs Normalization Layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-0.9512, -0.7509],\n",
              "          [-0.5507, -0.3504]]],\n",
              "\n",
              "\n",
              "        [[[-0.1502,  0.0501],\n",
              "          [ 0.2503,  2.4531]]]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Manually \n",
        "var=a.var([0,2,3],unbiased=False)\n",
        "mean=a.mean([0,2,3])\n",
        "(a-mean)/torch.sqrt(var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-0.9512, -0.7509],\n",
              "          [-0.5507, -0.3504]]],\n",
              "\n",
              "\n",
              "        [[[-0.1502,  0.0501],\n",
              "          [ 0.2503,  2.4531]]]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# using PyTorch BatchNorm2d\n",
        "with torch.no_grad():\n",
        "    norm=nn.BatchNorm2d(num_features=1)  \n",
        "    b=norm(a)\n",
        "b"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convolution Network for CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to ensure reproducibility\n",
        "seed=9 \n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "# use/not use batch normalization\n",
        "use_BN=False\n",
        "epochs=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor()\n",
        "dataset_train=vision.datasets.CIFAR10(\".\",download=True,train=True,transform=transform)\n",
        "dataset_test=vision.datasets.CIFAR10(\".\",download=True,train=False,transform=transform)\n",
        "loader_train=DataLoader(dataset_train,batch_size=64,shuffle=True,num_workers=2)\n",
        "loader_test=DataLoader(dataset_test,batch_size=512,shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,norm_layers=True):\n",
        "    super().__init__()\n",
        "    self.norm_layers=norm_layers\n",
        "    # self.norm1=nn.BatchNorm2d(32)\n",
        "    # self.norm2=nn.BatchNorm2d(32)\n",
        "    # self.norm3=nn.BatchNorm2d(64)\n",
        "    # self.norm4=nn.BatchNorm2d(64)\n",
        "    self.norm1=nn.Dropout2d(0.5)\n",
        "    self.norm2=nn.Dropout2d(0.5)\n",
        "    self.norm3=nn.Dropout2d(0.5)\n",
        "    self.norm4=nn.Dropout2d(0.5)\n",
        "\n",
        "    self.relu=nn.ReLU()\n",
        "    # input is (*,3,32,32)\n",
        "    self.conv1=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3)\n",
        "    # input is (*,32,30,30)\n",
        "    self.conv2=nn.Conv2d(in_channels=32,out_channels=32,kernel_size=3)\n",
        "    # input is (*,32,28,28)\n",
        "    self.pool1=nn.MaxPool2d(kernel_size=(2,2))\n",
        "    # input is (*,32,14,14)\n",
        "    self.conv3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3)\n",
        "    # input is (*,64,12,12)\n",
        "    self.conv4=nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3)\n",
        "    # input is (*,64,10,10)\n",
        "    self.pool2=nn.MaxPool2d(kernel_size=(2,2))\n",
        "    # input is (*,64,5,5)\n",
        "    self.flatten=nn.Flatten()\n",
        "    # input is (*,64x5x5)\n",
        "    self.fc1=nn.Linear(in_features=5*5*64,out_features=128)\n",
        "    self.fc2=nn.Linear(in_features=128,out_features=10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.conv1(x)\n",
        "    if self.norm_layers:\n",
        "      x=self.norm1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv2(x)\n",
        "    if self.norm_layers:\n",
        "      x=self.norm2(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.pool1(x)\n",
        "    \n",
        "    x=self.conv3(x)\n",
        "    if self.norm_layers:\n",
        "      x=self.norm3(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.conv4(x)\n",
        "    if self.norm_layers:\n",
        "      x=self.norm4(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.pool2(x)\n",
        "    \n",
        "    x=self.flatten(x)\n",
        "    x=self.fc1(x)\n",
        "    x=self.relu(x)\n",
        "    x=self.fc2(x)\n",
        "    return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(model,batch,loss_fn):\n",
        "    imgs,labels=batch\n",
        "    imgs=imgs.cuda()\n",
        "    labels=labels.cuda()\n",
        "    outputs=model(imgs)\n",
        "    _,pred=torch.max(outputs,dim=1)\n",
        "    acc=torch.sum(pred==labels).item()\n",
        "    loss=loss_fn(outputs,labels)\n",
        "    return loss,torch.tensor(acc/len(labels))\n",
        "\n",
        "@torch.no_grad() \n",
        "def evaluate(model,loader,loss_fn):\n",
        "    model.eval()\n",
        "    # crit is a list of pairs of tensors\n",
        "    crit=[accuracy(model,batch,loss_fn) for batch in loader]\n",
        "    crit=torch.tensor(crit)\n",
        "    m=crit.mean(dim=0)\n",
        "    loss=m[0]\n",
        "    acc=m[1]\n",
        "    return loss,acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=Net(norm_layers=use_BN).cuda()\n",
        "optimizer=Adam(model.parameters())\n",
        "#optimizer=SGD(model.parameters(),lr=0.5)\n",
        "loss_fn=nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Enabling eager execution\n",
            "INFO:tensorflow:Enabling v2 tensorshape\n",
            "INFO:tensorflow:Enabling resource variables\n",
            "INFO:tensorflow:Enabling tensor equality\n",
            "INFO:tensorflow:Enabling control flow v2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "# To display tensorboard inside the notebook\n",
        "%load_ext tensorboard\n",
        "current=datetime.datetime.now()\n",
        "log_dir = 'logs/tensorboard/' + ('with-BN-' if use_BN else 'without-BN-')+current.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "writer=SummaryWriter(log_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EarlyStopping():\n",
        "    def __init__(self,patience=4,tolerance=0):\n",
        "        self.patience=patience\n",
        "        self.tolerance=tolerance\n",
        "        self.min_loss=float('inf')\n",
        "        self.count=0\n",
        "    def __call__(self,loss):\n",
        "        if loss<self.min_loss:\n",
        "            self.count=0\n",
        "            self.min_loss=loss\n",
        "            return False\n",
        "        elif loss>self.min_loss+self.tolerance:\n",
        "            self.count+=1\n",
        "            if self.count>self.patience:\n",
        "                return True\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/50]: 100%|██████████| 782/782 [00:32<00:00, 24.33it/s, loss=1.42] \n",
            "Epoch [2/50]: 100%|██████████| 782/782 [00:26<00:00, 29.97it/s, loss=1.17] \n",
            "Epoch [3/50]: 100%|██████████| 782/782 [00:17<00:00, 45.95it/s, loss=1.1]  \n",
            "Epoch [4/50]: 100%|██████████| 782/782 [00:16<00:00, 47.77it/s, loss=1.03]  \n",
            "Epoch [5/50]: 100%|██████████| 782/782 [00:15<00:00, 49.35it/s, loss=0.868] \n",
            "Epoch [6/50]: 100%|██████████| 782/782 [00:15<00:00, 49.65it/s, loss=0.865] \n",
            "Epoch [7/50]: 100%|██████████| 782/782 [00:16<00:00, 48.60it/s, loss=0.849] \n",
            "Epoch [8/50]: 100%|██████████| 782/782 [00:16<00:00, 47.77it/s, loss=0.868] \n",
            "Epoch [9/50]: 100%|██████████| 782/782 [00:16<00:00, 47.63it/s, loss=0.738] \n",
            "Epoch [10/50]: 100%|██████████| 782/782 [00:15<00:00, 48.89it/s, loss=0.702] \n",
            "Epoch [11/50]: 100%|██████████| 782/782 [00:16<00:00, 46.61it/s, loss=0.649] \n",
            "Epoch [12/50]: 100%|██████████| 782/782 [00:16<00:00, 47.03it/s, loss=0.626] \n",
            "Epoch [13/50]: 100%|██████████| 782/782 [00:16<00:00, 47.27it/s, loss=0.694] \n",
            "Epoch [14/50]: 100%|██████████| 782/782 [00:17<00:00, 45.66it/s, loss=0.594]\n",
            "Epoch [15/50]: 100%|██████████| 782/782 [00:16<00:00, 46.84it/s, loss=0.553] \n",
            "Epoch [16/50]: 100%|██████████| 782/782 [00:18<00:00, 42.79it/s, loss=0.635] \n",
            "Epoch [17/50]: 100%|██████████| 782/782 [00:16<00:00, 46.02it/s, loss=0.543] \n",
            "Epoch [18/50]: 100%|██████████| 782/782 [00:17<00:00, 45.60it/s, loss=0.519] \n",
            "Epoch [19/50]: 100%|██████████| 782/782 [00:17<00:00, 45.58it/s, loss=0.496] \n",
            "Epoch [20/50]: 100%|██████████| 782/782 [00:17<00:00, 45.50it/s, loss=0.422] \n",
            "Epoch [21/50]: 100%|██████████| 782/782 [00:16<00:00, 46.15it/s, loss=0.481] \n",
            "Epoch [22/50]: 100%|██████████| 782/782 [00:17<00:00, 43.46it/s, loss=0.417] \n",
            "Epoch [23/50]: 100%|██████████| 782/782 [00:17<00:00, 45.14it/s, loss=0.412] \n",
            "Epoch [24/50]: 100%|██████████| 782/782 [00:16<00:00, 46.26it/s, loss=0.494] \n",
            "Epoch [25/50]: 100%|██████████| 782/782 [00:17<00:00, 44.60it/s, loss=0.345] \n",
            "Epoch [26/50]: 100%|██████████| 782/782 [00:17<00:00, 45.03it/s, loss=0.419] \n",
            "Epoch [27/50]: 100%|██████████| 782/782 [00:17<00:00, 45.75it/s, loss=0.326] \n",
            "Epoch [28/50]: 100%|██████████| 782/782 [00:17<00:00, 45.51it/s, loss=0.346] \n",
            "Epoch [29/50]: 100%|██████████| 782/782 [00:18<00:00, 41.94it/s, loss=0.344] \n",
            "Epoch [30/50]: 100%|██████████| 782/782 [00:17<00:00, 43.47it/s, loss=0.241] \n",
            "Epoch [31/50]: 100%|██████████| 782/782 [00:17<00:00, 44.29it/s, loss=0.319] \n",
            "Epoch [32/50]: 100%|██████████| 782/782 [00:17<00:00, 44.39it/s, loss=0.284] \n",
            "Epoch [33/50]: 100%|██████████| 782/782 [00:17<00:00, 44.83it/s, loss=0.243] \n",
            "Epoch [34/50]: 100%|██████████| 782/782 [00:17<00:00, 44.39it/s, loss=0.192] \n",
            "Epoch [35/50]: 100%|██████████| 782/782 [00:18<00:00, 42.37it/s, loss=0.253]  \n",
            "Epoch [36/50]: 100%|██████████| 782/782 [00:17<00:00, 44.01it/s, loss=0.379]  \n",
            "Epoch [37/50]: 100%|██████████| 782/782 [00:17<00:00, 43.61it/s, loss=0.268] \n",
            "Epoch [38/50]: 100%|██████████| 782/782 [00:17<00:00, 43.88it/s, loss=0.307]  \n",
            "Epoch [39/50]: 100%|██████████| 782/782 [00:17<00:00, 44.68it/s, loss=0.225] \n",
            "Epoch [40/50]: 100%|██████████| 782/782 [00:17<00:00, 43.99it/s, loss=0.18]  \n",
            "Epoch [41/50]: 100%|██████████| 782/782 [00:18<00:00, 42.72it/s, loss=0.234]  \n",
            "Epoch [42/50]: 100%|██████████| 782/782 [00:17<00:00, 45.98it/s, loss=0.212] \n",
            "Epoch [43/50]: 100%|██████████| 782/782 [00:17<00:00, 45.19it/s, loss=0.212]  \n",
            "Epoch [44/50]: 100%|██████████| 782/782 [00:17<00:00, 44.22it/s, loss=0.159]  \n",
            "Epoch [45/50]: 100%|██████████| 782/782 [00:17<00:00, 45.23it/s, loss=0.156]  \n",
            "Epoch [46/50]: 100%|██████████| 782/782 [00:17<00:00, 44.64it/s, loss=0.173] \n",
            "Epoch [47/50]: 100%|██████████| 782/782 [00:17<00:00, 44.43it/s, loss=0.167] \n",
            "Epoch [48/50]: 100%|██████████| 782/782 [00:17<00:00, 44.02it/s, loss=0.189]  \n",
            "Epoch [49/50]: 100%|██████████| 782/782 [00:17<00:00, 44.75it/s, loss=0.274]  \n",
            "Epoch [50/50]: 100%|██████████| 782/782 [00:17<00:00, 44.84it/s, loss=0.179] \n"
          ]
        }
      ],
      "source": [
        "trigger=True\n",
        "es=EarlyStopping()\n",
        "from tqdm import tqdm\n",
        "for epoch in range(epochs):\n",
        "  loop=tqdm(loader_train)\n",
        "  loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
        "  epoch_loss=0.\n",
        "  model.train()\n",
        "  for (imgs,labels) in loop:\n",
        "    optimizer.zero_grad()\n",
        "    imgs=imgs.cuda()\n",
        "    labels=labels.cuda()\n",
        "    outputs=model(imgs)\n",
        "    loss=loss_fn(outputs,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss=0.9*epoch_loss+0.1*loss.item()\n",
        "    loop.set_postfix(loss=epoch_loss)\n",
        "   \n",
        "  t_loss,t_acc=evaluate(model,loader_train,loss_fn)\n",
        "  v_loss,v_acc=evaluate(model,loader_test,loss_fn)\n",
        "  writer.add_scalar(\"Epoch loss\",epoch_loss,epoch)\n",
        "  writer.add_scalars(\"loss\",{'train':t_loss,'valid':v_loss},epoch)\n",
        "  writer.add_scalars(\"acc\",{'train':t_acc,'valid':v_acc},epoch)\n",
        "  # if es(v_loss) and trigger:\n",
        "  #   break\n",
        "  #   print(\"At epoch={} we should stop. Validation accuracy={}\".format(epoch,v_acc))\n",
        "  #   trigger=False\n",
        "writer.close()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2023-01-08 10:05:50.577724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\n",
              "I0108 10:05:54.671122 26884 plugin.py:429] Monitor runs begin\n",
              "Traceback (most recent call last):\n",
              "  File \"c:\\python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
              "    return _run_code(code, main_globals, None,\n",
              "  File \"c:\\python39\\lib\\runpy.py\", line 87, in _run_code\n",
              "    exec(code, run_globals)\n",
              "  File \"C:\\Python39\\Scripts\\tensorboard.exe\\__main__.py\", line 7, in <module>\n",
              "  File \"c:\\python39\\lib\\site-packages\\tensorboard\\main.py\", line 46, in run_main\n",
              "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
              "  File \"c:\\python39\\lib\\site-packages\\absl\\app.py\", line 303, in run\n",
              "    _run_main(main, args)\n",
              "  File \"c:\\python39\\lib\\site-packages\\absl\\app.py\", line 251, in _run_main\n",
              "    sys.exit(main(argv))\n",
              "  File \"c:\\python39\\lib\\site-packages\\tensorboard\\program.py\", line 276, in main\n",
              "    return runner(self.flags) or 0\n",
              "  File \"c:\\python39\\lib\\site-packages\\tensorboard\\program.py\", line 292, in _run_serve_subcommand\n",
              "    server = self._make_server()\n",
              "  File \"c:\\python39\\lib\\site-packages\\tensorboard\\program.py\", line 467, in _make_server\n",
              "    app = application.TensorBoardWSGIApp(\n",
              "  File \"c:\\python39\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 139, in TensorBoardWSGIApp\n",
              "    return TensorBoardWSGI(\n",
              "  File \"c:\\python39\\lib\\site-packages\\tensorboard\\backend\\application.py\", line 252, in __init__\n",
              "    raise ValueError(\n",
              "ValueError: Duplicate plugins for name projector"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir logs/tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchmetrics in c:\\python39\\lib\\site-packages (0.11.0)\n",
            "Requirement already satisfied: packaging in c:\\python39\\lib\\site-packages (from torchmetrics) (21.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in c:\\python39\\lib\\site-packages (from torchmetrics) (1.12.1+cu116)\n",
            "Requirement already satisfied: numpy>=1.17.2 in c:\\python39\\lib\\site-packages (from torchmetrics) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in c:\\python39\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\python39\\lib\\site-packages (from packaging->torchmetrics) (2.4.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
            "WARNING: You are using pip version 21.2.4; however, version 22.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "__new__() missing 1 required positional argument: 'task'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-14-967286d48955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install torchmetrics'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconmat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mconmat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mTypeError\u001b[0m: __new__() missing 1 required positional argument: 'task'"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "from torchmetrics import ConfusionMatrix\n",
        "conmat=ConfusionMatrix(num_classes=10)\n",
        "conmat=conmat.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total=0\n",
        "correct=0\n",
        "for data in loader_test:\n",
        "  imgs,labels=data\n",
        "  imgs=imgs.cuda()\n",
        "  labels=labels.cuda()\n",
        "  outputs=model(imgs)\n",
        "  # the second return value is the index of the max i.e. argmax\n",
        "  _,predicted=torch.max(outputs.data,1)\n",
        "  correct+=(predicted==labels).sum()\n",
        "  total+=labels.size()[0]\n",
        "  conmat.update(predicted,labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "x=conmat.compute().cpu().numpy()\n",
        "plt.figure(figsize=(10,7))\n",
        "sb.heatmap(x,xticklabels=dataset_train.classes,yticklabels=dataset_train.classes,annot=True,fmt=\".0f\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- The rows are the actual images and the columns are the prediction (How can you check?)\n",
        "- While the prediction accuracy is good albeit not impressive\n",
        "- From the confusion matrix we find justifications for the inaccuracies\n",
        "- For example\n",
        "    - most of the incorrect classifications of automobiles were classified as trucks\n",
        "    - most of the incorrect classifications of cats/dogs were classified as dogs/cats\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
