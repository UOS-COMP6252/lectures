{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as vision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"400\"\n",
       "            src=\"animate.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x21857dae820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"animate.pdf\", width=600, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $s,i,j,f$ be the number of samples,output height index,output width index, and the filter index respectively. The convolution operation is defined as\n",
    "\\begin{align*}\n",
    "O_{s,f,i,j}=\\sum_c\\sum_{m,n}X_{s,c,i+m,j+n}*K_{f,c,m,n}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following:\n",
    "\n",
    "1. The **depth** of every filter **must** be equal to the number of input channels\n",
    "1. A filter has different values for each input channel\n",
    "1. The convolution operation sums the contributions from all the channels\n",
    "1. Therefore the number of output channels is exactly equal to the number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "# a and b have 1 channel and dimension 4x4\n",
    "a=torch.ones([1,4,4])\n",
    "b=torch.ones([1,4,4])\n",
    "# stack a and b together to create a sample of size 2\n",
    "c=torch.stack([a,b])\n",
    "\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "# the in_channels must be 1 to match # channels of a and b\n",
    "l=nn.Conv2d(in_channels=1,out_channels=3,kernel_size=2,bias=False)\n",
    "with torch.no_grad():\n",
    "    l.weight.fill_(1.)\n",
    "p=l.parameters()\n",
    "p0=next(p)\n",
    "print(p0.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4., 4., 4.],\n",
       "          [4., 4., 4.],\n",
       "          [4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.],\n",
       "          [4., 4., 4.],\n",
       "          [4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.],\n",
       "          [4., 4., 4.],\n",
       "          [4., 4., 4.]]],\n",
       "\n",
       "\n",
       "        [[[4., 4., 4.],\n",
       "          [4., 4., 4.],\n",
       "          [4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.],\n",
       "          [4., 4., 4.],\n",
       "          [4., 4., 4.]],\n",
       "\n",
       "         [[4., 4., 4.],\n",
       "          [4., 4., 4.],\n",
       "          [4., 4., 4.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=l(c)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
