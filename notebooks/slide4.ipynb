{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as vision\n",
    "import torch.nn as nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following:\n",
    "\n",
    "1. The **depth** of every filter **must** be equal to the number of input channels\n",
    "1. A filter has different values for each input channel\n",
    "1. The convolution operation sums the contributions from all the channels\n",
    "1. Therefore the number of output channels is exactly equal to the number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's size=[2, 2, 3, 3]\n",
      "a[0]=\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "a[1]=\n",
      "[[3. 3. 3.]\n",
      " [3. 3. 3.]\n",
      " [3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# a and b have 1 channel and dimension 4x4\n",
    "a=torch.ones([2,3,3])\n",
    "a[1,:,:]=3.\n",
    "b=torch.ones([2,3,3])\n",
    "# stack a and b together to create a sample of size 2\n",
    "x=torch.stack([a,b])\n",
    "\n",
    "print(\"X's size={}\".format(list(x.size())))\n",
    "print(\"a[0]=\\n{}\".format(a[0].numpy()))\n",
    "print(\"a[1]=\\n{}\".format(a[1].numpy()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall dimensions used in the convolution operation.\n",
    "Let $s,i,j,f$ be the number of samples,output height index,output width index, and the filter index respectively. The convolution operation is defined as\n",
    "\\begin{align*}\n",
    "O_{s,f,i,j}=b_f+ \\sum_c\\sum_{m,n}X_{s,c,i+m,j+n}*K_{f,c,m,n}\n",
    "\\end{align*}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The ```c``` dimensions is fixed by the number of channels in the input.\n",
    "- In the case of ```a```, ```b```, and by extension ```x```, the # of channels is 2\n",
    "- In this example we choose 3 filters, each with height and width of 2x2\n",
    "- In Pytorch a convolution layer is created as follows\n",
    "\n",
    "```nn.Conv2d(in_channels=2,out_channels=3,kernel_size=2,bias=False)```\n",
    "- Note that we chose to omit the bias for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter idx=3,channel=2,height=2,width=2\n"
     ]
    }
   ],
   "source": [
    "# the in_channels must be 2 to match # channels of a and b\n",
    "l=nn.Conv2d(in_channels=2,out_channels=3,kernel_size=2,bias=False)\n",
    "with torch.no_grad():\n",
    "    # all values set to 1 except the second channel to 3 (for all filters)\n",
    "    l.weight.fill_(1.)\n",
    "    l.weight[:,1,:,:].fill_(3.)\n",
    "p=l.parameters()\n",
    "w=next(p)\n",
    "s=w.size()\n",
    "print(\"filter idx={},channel={},height={},width={}\".format(s[0],s[1],s[2],s[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output samples=2,channels=3,height=2,width=2\n"
     ]
    }
   ],
   "source": [
    "d=l(x)\n",
    "s=d.size()\n",
    "print(\"output samples={},channels={},height={},width={}\".format(s[0],s[1],s[2],s[3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the output for the first sample (the convolution of ```a```). Since all the kernels are the same we inspect one output channel. Therefore, we are considering the values in ```d[0,0,:,:]```.\n",
    "\n",
    "```a``` has two input channels: the first has values all ones and the second all 3s.\n",
    "The filter has values ones for the first channel and 3s for the second. Since the receptive field is 2x2 then the convolution would result in:\n",
    "\\begin{align*}\n",
    "(1\\times 1+1\\times 1+1\\times 1+1\\times 1)+(3\\times 3+3\\times 3+3\\times 3+3\\times 3)\\\\\n",
    "=40\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40. 40.]\n",
      " [40. 40.]]\n",
      "[[40. 40.]\n",
      " [40. 40.]]\n",
      "[[40. 40.]\n",
      " [40. 40.]]\n"
     ]
    }
   ],
   "source": [
    "# convolution of a\n",
    "print(d[0,0,:,:].detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the second sample (the convolution of ```b```) is similar\n",
    "\\begin{align*}\n",
    "(1\\times 1+1\\times 1+1\\times 1+1\\times 1)+(1\\times 3+1\\times 3+1\\times 3+1\\times 3)\\\\\n",
    "=16\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16. 16.]\n",
      " [16. 16.]]\n"
     ]
    }
   ],
   "source": [
    "# convolution of b\n",
    "print(d[1,0,:,:].detach().numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max pooling\n",
    "\n",
    "- Recall that max pooling with kernel size $h\\times w$ and stride $s$ computes the maximum value of the input in the window $h\\times w$.\n",
    "- It then \"slides\" that window by $s$.\n",
    "- Max pooling is performed in PyTorch using ```nn.MaxPool2d```\n",
    "- Example:\n",
    "- Input is a single channel with size 3x3\n",
    "- By default the kernel is square so specifying 2 means 2x2\n",
    "- By default the stride is the same as the kernel size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.]]\n",
      "\n",
      " [[14.]]]\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],[4,5,6],[7,8,9]],dtype=torch.float32)\n",
    "b=torch.tensor([[10,11,12],[13,14,15],[16,17,18]],dtype=torch.float32)\n",
    "# stack a and b together to create a sample of size 2\n",
    "x=torch.stack([a,b])\n",
    "\n",
    "# By default a square kernel so 2 is the same as 2x2\n",
    "# If the stride is no specified it defaults to kernel size\n",
    "maxpool=nn.MaxPool2d(2)\n",
    "y=maxpool(x)\n",
    "print(y.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice how the above has a single value. \n",
    "- Because when a stride of 2 is applied the kernel \"overshoots\" the input\n",
    "- Therefore only a single computation is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.,  6.],\n",
      "         [ 8.,  9.]],\n",
      "\n",
      "        [[14., 15.],\n",
      "         [17., 18.]]])\n"
     ]
    }
   ],
   "source": [
    "maxpool=nn.MaxPool2d(kernel_size=2,stride=1)\n",
    "y=maxpool(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
