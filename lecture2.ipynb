{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    " We mentioned in lecture 1 that PyTorch can compute the gradient to any function. In this case we have indirections.\n",
    " PyTorch builds a computation graph and uses the chain rule\n",
    " we introduce with an example\n",
    "\n",
    " As an example, consider the following computations:\n",
    "\n",
    " $a=2$\n",
    " \n",
    " $b=4$\n",
    " \n",
    " $c=a+b$\n",
    " \n",
    " $d=\\log(a)*\\log(b)$\n",
    "\n",
    " $e=c*d$\n",
    "\n",
    " When a gradient is needed, PyTorch builds a **computational graph** to perform the operations as shown in the figure below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comp-graph-1](comp-graph1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Suppose that we need to compute the gradient of $e$ with respect to $a$ and $b$. Using the chain rule we know that\n",
    " $$\\frac{\\partial e}{\\partial a}=\\frac{\\partial e}{\\partial c}\\frac{\\partial c}{\\partial a}+\\frac{\\partial e}{\\partial d}\\frac{\\partial d}{\\partial a}$$\n",
    " $$\\frac{\\partial e}{\\partial b}=\\frac{\\partial e}{\\partial c}\\frac{\\partial c}{\\partial b}+\\frac{\\partial e}{\\partial d}\\frac{\\partial d}{\\partial b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the gradient is needed, PyTorch creates auxiliary nodes in the computation graph to help with the gradient computation. Considering that for every operation performed, PyTorch already knows its derivative, PyTorch builds as shown in the figure below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comp-graph-2](comp-graph2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the graph is built with all the necessary nodes, PyTorch \"Walks backward\" in the computational graph to compute the gradients as shown in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![backprop](backprop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code corresponding for the above computations. Let us consider it step by step.\n",
    "1. After defining $a$ and $b$, with ```requires_grad=True``` we are declaring that we need to compute the gradient as some point.\n",
    "1. ```c=a+b``` a node is created for $c$ where the operation is ```+``` and the inputs are $a$ and $b$. Automatically, PyTorch creates two auxillary nodes (actually they are functions, but it is easier to visualize as nodes) that compute $\\frac{\\partial c}{\\partial a}$ and  $\\frac{\\partial c}{\\partial b}$\n",
    "1. $d=\\log a*\\log b$. As before, PyTorch creates a node for $d$ where the operations are ```*``` and ```log```. (Actually it creates the subtree shown below but for the sake of simplicity we visualize it as a single node) and, crucially, PyTorch already knows the derivative for all the primitive operations.\n",
    "1. ```e=c*d``` this similar to the second step ```c=a+b``` but the operation now is ```*```.\n",
    "1. Finally ```e.backward()``` is called which starts from node ```e``` and recursively computes the gradient using the already created nodes.\n",
    "1. For example, there are two paths leading to a from e. The first one gives 1x2x1 and the second 1x6x1.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(4.,requires_grad=True)\n",
    "c=a+b\n",
    "d=torch.log(a)*torch.log(b)\n",
    "e=c*d\n",
    "e.backward()\n",
    "print(a.grad,b.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
